---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: &app ollama
spec:
  interval: 30m
  chart:
    spec:
      chart: app-template
      version: 4.4.0
      sourceRef:
        kind: HelmRepository
        name: bjw-s
        namespace: flux-system
  values:
    defaultPodOptions:
      resourceClaims:
        - name: gpu
          resourceClaimTemplateName: ollama-gpu
    controllers:
      *app :
        type: statefulset
        annotations:
          reloader.stakater.com/auto: "true"
        containers:
          *app :
            image:
              repository: docker.io/ollama/ollama
              tag: 0.12.6
            env:
              LIBVA_DRIVER_NAME: i965
              OLLAMA_HOST: 0.0.0.0
              OLLAMA_ORIGINS: "*"
              # OLLAMA_MODELS: &pvc /models
              OLLAMA_GPU_ENABLED: "true"
            resources:
              claims:
                - name: gpu
              requests:
                cpu: 2000m
                memory: 8Gi
              limits:
                memory: 16Gi
    service:
      *app :
        controller: *app
        type: LoadBalancer
        annotations:
          coredns.io/hostname: ollama-lb
        ports:
          http:
            port: 11434
    persistence:
      config:
        enabled: true
        existingClaim: ${VOLSYNC_CLAIM}
        globalMounts:
          - path: /root/.ollama
      tmp:
        enabled: true
        type: emptyDir
        medium: Memory
        globalMounts:
          - path: /tmp
